{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "kD8iHVMkYCkO"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Badm0nting/stable-diffusion/blob/main/stable_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SETUP**"
      ],
      "metadata": {
        "id": "kbRwbwqSctxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade diffusers transformers accelerate mediapy omegaconf"
      ],
      "metadata": {
        "id": "ufD_d64nr08H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf"
      ],
      "metadata": {
        "id": "tpHSiSaGVEKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_refiner = False"
      ],
      "metadata": {
        "id": "hRVsA7iYxpMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MODEL**"
      ],
      "metadata": {
        "id": "AKF4Z-HYYMf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Model\n",
        "# @markdown IF U WANT TO USE ANOTHER MODEL, GO TO [HERE](https://huggingface.co/models?pipeline_tag=text-to-image&sort=trending), MAKE SURE THE MODEL HAVE A SAFETENSORS FILE\n",
        "\n",
        "import mediapy as media\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "model = \"digiplay/Realisian_v5\" # @param [\"digiplay/Realisian_v5\", \"stabilityai/stable-diffusion-xl-base-1.0\", \"hakurei/waifu-diffusion\", \"Linaqruf/anything-v3.0\"]\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False\n",
        ")\n",
        "\n",
        "pipe = pipe.to(\"cuda\")  # If you have a GPU for acceleration"
      ],
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**PROMPT**##"
      ],
      "metadata": {
        "id": "IZQKThVlmTeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PROMPT { display-mode: \"form\" }\n",
        "import os\n",
        "prompt = \"lebron james\" #@param {type:\"string\"}\n",
        "seed = 3442633626 # @param {type:\"slider\", min:0, max:9000000000, step:1}\n",
        "\n",
        "negative_prompt = \"bad-picture-chill-75v, ng_deepnegative_v1_75t, badhandv4, (worst quality:2), (low quality:2), (normal quality:2), (lowres:2), (bad anatomy:2), (bad hands:2), (watermark:2), (mole:1.5), (freckles:1.5)\" #@param {type:\"string\"}\n",
        "\n",
        "width = 512  #@param {type:\"slider\", min:8, max:2048, step:8}\n",
        "height = 720  #@param {type:\"slider\", min:8, max:2048, step:8}\n",
        "\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    negative_prompt=negative_prompt,\n",
        "    output_type=\"latent\" if use_refiner else \"pil\",\n",
        "    generator=torch.Generator().manual_seed(seed)\n",
        ").images\n",
        "if use_refiner:\n",
        "  images = refiner(\n",
        "      prompt = prompt,\n",
        "      negative_prompt = negative_prompt,\n",
        "      image = images,\n",
        "      ).images\n",
        "\n",
        "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
        "base_filename = \"output.jpg\"\n",
        "new_filename = base_filename\n",
        "if os.path.exists(base_filename):\n",
        "    index = 1\n",
        "    while True:\n",
        "        new_filename = f\"output_{index}.jpg\"\n",
        "        if not os.path.exists(new_filename):\n",
        "            break\n",
        "        index += 1\n",
        "images[0].save(new_filename)\n",
        "media.show_images(images)"
      ],
      "metadata": {
        "id": "AUc4QJfE-uR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TOOLS**"
      ],
      "metadata": {
        "id": "kD8iHVMkYCkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FIX FALSE NSFW\n",
        "pipe.safety_checker = None\n",
        "pipe.requires_safety_checker = False"
      ],
      "metadata": {
        "id": "xvpkelwnWQ1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}